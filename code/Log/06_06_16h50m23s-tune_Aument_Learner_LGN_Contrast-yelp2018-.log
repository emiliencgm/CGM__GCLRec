==========config==========
{'GTN_K': 3,
 'GTN_alpha': 0.3,
 'adaptive_method': 'None',
 'alpha': 0.5,
 'augment': 'Learner',
 'batch_size': 2048,
 'centroid_mode': 'eigenvector',
 'comment': 'tune_Aument_Learner_LGN_Contrast',
 'commonNeighbor_mode': 'SC',
 'cores': 10,
 'dataset': 'yelp2018',
 'device': device(type='cuda'),
 'early_stop_steps': 40,
 'edge_drop_prob': 0.1,
 'epoch_only_pop_for_BCloss': 5,
 'epochs': 1000,
 'eps_SimGCL': 0.1,
 'epsilon_GCLRec': 0.1,
 'group': '-',
 'if_SVD': 1,
 'if_big_matrix': 0,
 'if_double_label': 1,
 'if_load_embedding': 0,
 'if_multicore': 1,
 'if_pretrain': 0,
 'if_projector': 0,
 'if_tensorboard': 1,
 'if_tsne': 1,
 'if_valid': 0,
 'if_visual': 0,
 'init_method': 'Normal',
 'item_emb': 0,
 'job_type': '-',
 'k_aug': 0,
 'lambda1': 0.1,
 'latent_dim_rec': 64,
 'loss': 'BPR_Contrast',
 'lr': 0.001,
 'model': 'LightGCN_PyG',
 'n_cluster': 10,
 'n_fold': 2,
 'name': 'name',
 'notes': '-',
 'num_layers': 3,
 'p_drop': 0.1,
 'perplexity': 50,
 'pop_gamma': 0.02,
 'pop_group': 10,
 'project': 'project',
 'seed': 2023,
 'sigma_gausse': 1.0,
 'svd_q': 5,
 'tag': None,
 'tau_plus': 0.1,
 'temp_tau': 0.2,
 'temp_tau_pop': 0.1,
 'test_u_batch_size': 2048,
 'topks': [20],
 'tsne_group': [0, 9],
 'tsne_points': 2000,
 'user_emb': 0,
 'visual_epoch': 1,
 'w_GCLRec': 0.1,
 'weight_decay': 0.0001}
==========config==========
[0;30;43m[DATALOADER--START][0m
loading [/home/cgm/code/CGM__GCLRec/data/yelp2018]
1237259 interactions for training
324147 interactions for testing
yelp2018 Sparsity : 0.0012958757851778647
loading adjacency matrix
successfully loaded...
[0;30;43mRemember to delete this pre-calculed mat while changing data split ![0m
yelp2018 is ready to go
[0;30;43m[DATALOADER--END][0m
[0;30;43m[PRECALCULATE--START][0m
precal cost :  0.8298869132995605
[0;30;43m[PRECALCULATE--END][0m
user:31668, item:38048
[0;30;43muse NORMAL distribution UI for Embedding[0m
GCL Model is ready to go!
[0;30;43m[AUGMENT][0m
[0;30;43m[TRAIN][0m
EPOCH[0]:loss nan
[0;30;43m[TEST][0m
{'precision': array([0.00149204]), 'recall': array([0.00348623]), 'recall_pop': {0: array([0.]), 1: array([0.]), 2: array([0.]), 3: array([9.47328534e-05]), 4: array([0.]), 5: array([0.]), 6: array([9.47328534e-05]), 7: array([3.15776178e-05]), 8: array([0.00040292]), 9: array([0.00618721])}, 'recall_pop_Contribute': {0: array([0.]), 1: array([0.]), 2: array([0.]), 3: array([7.93826225e-06]), 4: array([0.]), 5: array([0.]), 6: array([1.93361647e-05]), 7: array([7.66885003e-06]), 8: array([7.26267612e-05]), 9: array([0.00337866])}, 'ndcg': array([0.0020213])}
[5;37;44mfind a better recall[0m [0;37;44m[0.00348623][0m [0;37;44m++[0.00348623][0m
time cost of epoch 0:  93.03437376022339
[0;30;43m[AUGMENT][0m
[0;30;43m[TRAIN][0m
EPOCH[1]:loss nan
[0;30;43m[TEST][0m
{'precision': array([0.00149204]), 'recall': array([0.00348623]), 'recall_pop': {0: array([0.]), 1: array([0.]), 2: array([0.]), 3: array([9.47328534e-05]), 4: array([0.]), 5: array([0.]), 6: array([9.47328534e-05]), 7: array([3.15776178e-05]), 8: array([0.00040292]), 9: array([0.00618721])}, 'recall_pop_Contribute': {0: array([0.]), 1: array([0.]), 2: array([0.]), 3: array([7.93826225e-06]), 4: array([0.]), 5: array([0.]), 6: array([1.93361647e-05]), 7: array([7.66885003e-06]), 8: array([7.26267612e-05]), 9: array([0.00337866])}, 'ndcg': array([0.0020213])}
time cost of epoch 1:  91.9514000415802
[0;30;43m[AUGMENT][0m
[0;30;43m[TRAIN][0m
EPOCH[2]:loss nan
[0;30;43m[TEST][0m
{'precision': array([0.00149204]), 'recall': array([0.00348623]), 'recall_pop': {0: array([0.]), 1: array([0.]), 2: array([0.]), 3: array([9.47328534e-05]), 4: array([0.]), 5: array([0.]), 6: array([9.47328534e-05]), 7: array([3.15776178e-05]), 8: array([0.00040292]), 9: array([0.00618721])}, 'recall_pop_Contribute': {0: array([0.]), 1: array([0.]), 2: array([0.]), 3: array([7.93826225e-06]), 4: array([0.]), 5: array([0.]), 6: array([1.93361647e-05]), 7: array([7.66885003e-06]), 8: array([7.26267612e-05]), 9: array([0.00337866])}, 'ndcg': array([0.0020213])}
time cost of epoch 2:  91.99742817878723
[0;30;43m[AUGMENT][0m
[0;30;43m[TRAIN][0m
