diff --git a/data/yelp2018/s_pre_adj_mat.npz b/data/yelp2018/s_pre_adj_mat.npz
deleted file mode 100644
index 4d4eb20..0000000
Binary files a/data/yelp2018/s_pre_adj_mat.npz and /dev/null differ
diff --git a/pyg_code/__pycache__/augment.cpython-310.pyc b/pyg_code/__pycache__/augment.cpython-310.pyc
index e202b2f..2def07f 100644
Binary files a/pyg_code/__pycache__/augment.cpython-310.pyc and b/pyg_code/__pycache__/augment.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/dataloader.cpython-310.pyc b/pyg_code/__pycache__/dataloader.cpython-310.pyc
index 1c60fd5..a1a4ae0 100644
Binary files a/pyg_code/__pycache__/dataloader.cpython-310.pyc and b/pyg_code/__pycache__/dataloader.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/homophily.cpython-310.pyc b/pyg_code/__pycache__/homophily.cpython-310.pyc
index 2105f99..c469e1c 100644
Binary files a/pyg_code/__pycache__/homophily.cpython-310.pyc and b/pyg_code/__pycache__/homophily.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/kmeans_gpu.cpython-310.pyc b/pyg_code/__pycache__/kmeans_gpu.cpython-310.pyc
index 77af26b..7f875a8 100644
Binary files a/pyg_code/__pycache__/kmeans_gpu.cpython-310.pyc and b/pyg_code/__pycache__/kmeans_gpu.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/loss.cpython-310.pyc b/pyg_code/__pycache__/loss.cpython-310.pyc
index f9257b5..abd528d 100644
Binary files a/pyg_code/__pycache__/loss.cpython-310.pyc and b/pyg_code/__pycache__/loss.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/model.cpython-310.pyc b/pyg_code/__pycache__/model.cpython-310.pyc
index 635c50f..7f41d74 100644
Binary files a/pyg_code/__pycache__/model.cpython-310.pyc and b/pyg_code/__pycache__/model.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/parse.cpython-310.pyc b/pyg_code/__pycache__/parse.cpython-310.pyc
index e3c7d51..151831c 100644
Binary files a/pyg_code/__pycache__/parse.cpython-310.pyc and b/pyg_code/__pycache__/parse.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/precalcul.cpython-310.pyc b/pyg_code/__pycache__/precalcul.cpython-310.pyc
index 31307ca..c1877cc 100644
Binary files a/pyg_code/__pycache__/precalcul.cpython-310.pyc and b/pyg_code/__pycache__/precalcul.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/procedure.cpython-310.pyc b/pyg_code/__pycache__/procedure.cpython-310.pyc
index 243bf99..e4a2ddc 100644
Binary files a/pyg_code/__pycache__/procedure.cpython-310.pyc and b/pyg_code/__pycache__/procedure.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/utils.cpython-310.pyc b/pyg_code/__pycache__/utils.cpython-310.pyc
index 40b27a3..18ac6de 100644
Binary files a/pyg_code/__pycache__/utils.cpython-310.pyc and b/pyg_code/__pycache__/utils.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/visual.cpython-310.pyc b/pyg_code/__pycache__/visual.cpython-310.pyc
index 7403999..19a022c 100644
Binary files a/pyg_code/__pycache__/visual.cpython-310.pyc and b/pyg_code/__pycache__/visual.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/world.cpython-310.pyc b/pyg_code/__pycache__/world.cpython-310.pyc
index 12fe0c4..9034de1 100644
Binary files a/pyg_code/__pycache__/world.cpython-310.pyc and b/pyg_code/__pycache__/world.cpython-310.pyc differ
diff --git a/pyg_code/dataloader.py b/pyg_code/dataloader.py
index 31e30e0..db33bf9 100644
--- a/pyg_code/dataloader.py
+++ b/pyg_code/dataloader.py
@@ -21,7 +21,7 @@ from time import time
 import networkx as nx
 from torch_geometric.data import Data
 
-class dataset(Dataset):
+class dataset():
     """
     Dataset type for pytorch \n
     Incldue graph information
@@ -355,24 +355,3 @@ class dataset(Dataset):
         edge_indice = torch.sparse.FloatTensor(index, val, (self.n_user, self.m_item))
         edge_indice = edge_indice.coalesce()
         return edge_indice
-
-    '''
-    Dataset的所有子类都应该重写方法__len__(), __getitem__()
-    '''
-    def __len__(self):
-        return self.traindataSize
-
-    def __getitem__(self, idx):
-        '''
-        input: user在trainUser列表中的idx
-        output: 随机三元组(user, pos, neg)
-        '''
-        user = self.trainUser[idx]
-        pos = random.choice(self._allPos[user])
-        while True:
-            neg = np.random.randint(0, self.m_item)
-            if neg in self._allPos[user]:
-                continue
-            else:
-                break
-        return user, pos, neg
diff --git a/pyg_code/loss.py b/pyg_code/loss.py
index 1775a6d..428b2d2 100644
--- a/pyg_code/loss.py
+++ b/pyg_code/loss.py
@@ -321,6 +321,7 @@ class Adaptive_softmax_loss(torch.nn.Module):
             #batch_weight_homophily = self.get_homophily(batch_user, batch_pos_item)
             batch_weight_pop_user, batch_weight_pop_item = torch.log(batch_weight_pop_user), torch.log(batch_weight_pop_item)
             batch_weight_centroid = self.get_centroid(batch_user, batch_pos_item, centroid=mode, aggr='mean', mode='GCA')
+            batch_weight_centroid = torch.ones_like(batch_weight_centroid)- batch_weight_centroid#TODO
             batch_weight_commonNeighbor1, batch_weight_commonNeighbor2 = self.get_commonNeighbor(batch_user, batch_pos_item)
             features = [batch_weight_pop_user, batch_weight_pop_item, batch_weight_centroid, batch_weight_commonNeighbor1, batch_weight_commonNeighbor2]
             
@@ -386,4 +387,110 @@ class Adaptive_softmax_loss(torch.nn.Module):
             raise TypeError('adaptive method not implemented')
 
         
-        return batch_weight
\ No newline at end of file
+        return batch_weight
+    
+class Adaptive_loss(torch.nn.Module):
+    def __init__(self, config, model:LightGCN, precal:precalculate, homophily:Homophily):
+        super(Adaptive_loss, self).__init__()
+
+        self.config = config
+        self.model = model
+        self.precal = precal
+        self.homophily = homophily
+        self.tau = config['temp_tau']
+        self.alpha = config['alpha']
+        self.f = lambda x: torch.exp(x / self.tau)
+        self.MLP_model = MLP(5+2*0).to(world.device)
+
+    def adaptive_loss(self, users_emb, pos_emb, ada_coef):
+        '''
+        '''
+        users_emb = F.normalize(users_emb, dim=1)
+        pos_emb = F.normalize(pos_emb, dim=1)
+        ratings = torch.matmul(users_emb, torch.transpose(pos_emb, 0, 1))
+        ratings_diag = torch.diag(ratings)
+        theta = torch.arccos(torch.clamp(ratings_diag,-1+1e-7,1-1e-7))
+        M = torch.arccos(torch.clamp(ada_coef,-1+1e-7,1-1e-7))
+        ratings_diag = torch.cos(theta + M)
+        numerator = torch.exp(ratings_diag / self.tau)
+        denominator = torch.sum(torch.exp(ratings / self.tau), dim = 1)
+        loss = torch.mean(torch.negative((2*self.alpha * torch.log(numerator) -  2*(1-self.alpha) * torch.log(denominator))))
+
+        return loss
+
+    def get_popdegree(self, batch_user, batch_pos_item):
+        with torch.no_grad():
+            pop_user = torch.tensor(self.precal.popularity.user_pop_degree_label).to(world.device)[batch_user]
+            pop_item = torch.tensor(self.precal.popularity.item_pop_degree_label).to(world.device)[batch_pos_item]
+        return pop_user, pop_item
+
+    def get_homophily(self, batch_user, batch_pos_item):
+        with torch.no_grad():
+            batch_user_prob, batch_item_prob = self.homophily.get_homophily_batch(batch_user, batch_pos_item)
+            batch_weight = torch.sum(torch.mul(batch_user_prob, batch_item_prob) ,dim=1)
+        return batch_weight    
+    
+    def get_centroid(self, batch_user, batch_pos_item, centroid='eigenvector', aggr='mean', mode='GCA'):
+        with torch.no_grad():
+            batch_weight = self.precal.centroid.cal_centroid_weights_batch(batch_user, batch_pos_item, centroid=centroid, aggr=aggr, mode=mode)
+        return batch_weight
+    
+    def get_commonNeighbor(self, batch_user, batch_pos_item):
+        with torch.no_grad():
+            n_users = self.model.num_users
+            csr_matrix_CN_simi = self.precal.common_neighbor.CN_simi_mat_sp
+            batch_user, batch_pos_item = np.array(batch_user.cpu()), np.array(batch_pos_item.cpu())
+            batch_weight1 = csr_matrix_CN_simi[batch_user, batch_pos_item+n_users]
+            batch_weight2 = csr_matrix_CN_simi[batch_pos_item+n_users, batch_user]
+            batch_weight1 = torch.tensor(np.array(batch_weight1).reshape((-1,))).to(world.device)
+            batch_weight2 = torch.tensor(np.array(batch_weight2).reshape((-1,))).to(world.device)
+        return batch_weight1, batch_weight2
+
+    def get_mlp_input(self, features):
+        '''
+        features = [tensor, tensor, ...]
+        '''
+        U = features[0].unsqueeze(0)
+        for i in range(1,len(features)):
+            U = torch.cat((U, features[i].unsqueeze(0)), dim=0)
+        return U.T
+
+
+    def get_coef_adaptive(self, batch_user, batch_pos_item, method='mlp', mode='eigenvector'):
+        '''
+        input: index batch_user & batch_pos_item\n
+        return tensor([adaptive coefficient of u_n-i_n])\n
+        the bigger, the more reliable, the more important
+        '''
+        if method == 'mlp':
+            batch_weight_pop_user, batch_weight_pop_item = self.get_popdegree(batch_user, batch_pos_item)
+            # batch_weight_pop_user = torch.ones_like(batch_weight_pop_user)*math.log(self.precal.popularity.max_pop_u)-torch.log(batch_weight_pop_user)#TODO problem of grandeur and +-
+            # batch_weight_pop_item = torch.ones_like(batch_weight_pop_item)*math.log(self.precal.popularity.max_pop_i)-torch.log(batch_weight_pop_item)
+            #batch_weight_homophily = self.get_homophily(batch_user, batch_pos_item)
+            batch_weight_pop_user, batch_weight_pop_item = torch.log(batch_weight_pop_user), torch.log(batch_weight_pop_item)
+            batch_weight_centroid = self.get_centroid(batch_user, batch_pos_item, centroid=mode, aggr='mean', mode='GCA')
+            batch_weight_centroid = torch.ones_like(batch_weight_centroid) - batch_weight_centroid#TODO 反向centroid
+            batch_weight_commonNeighbor1, batch_weight_commonNeighbor2 = self.get_commonNeighbor(batch_user, batch_pos_item)
+            features = [batch_weight_pop_user, batch_weight_pop_item, batch_weight_centroid, batch_weight_commonNeighbor1, batch_weight_commonNeighbor2]
+            
+            # for i in range(self.config['latent_dim_rec']):
+            #     features.append(batch_weight_emb_user[:,i])
+            # for i in range(self.config['latent_dim_rec']):
+            #     features.append(batch_weight_emb_item[:,i])
+            
+            batch_weight = self.get_mlp_input(features)
+            batch_weight = self.MLP_model(batch_weight)
+
+        else:
+            batch_weight = None
+            raise TypeError('adaptive method not implemented')
+        
+        self.batch_weight = batch_weight
+        return batch_weight
+    
+
+class IRM():
+    def __init__(self, loss):
+        self.loss = loss
+    def irm_reg(self, batch):
+        return 
\ No newline at end of file
diff --git a/pyg_code/main.py b/pyg_code/main.py
index 495e796..7a28460 100644
--- a/pyg_code/main.py
+++ b/pyg_code/main.py
@@ -45,6 +45,7 @@ def plot_MLP(epoch, precal, total_loss):
             for i in pop_i:
                 a = [0.]*(5+2*0)
                 a[1] = math.log(i)
+                # a[1] = i
                 input_mlp_batch.append(a)
             input_mlp_batch = torch.Tensor(input_mlp_batch).to(world.device)
             output_mlp_batch = total_loss.MLP_model(input_mlp_batch)
@@ -103,7 +104,7 @@ def main():
     notes = world.config['notes']
     group = world.config['group']
     job_type = world.config['job_type']
-    os.environ['WANDB_MODE'] = 'dryrun'#TODO WandB上传
+    # os.environ['WANDB_MODE'] = 'dryrun'#TODO WandB上传
     wandb.init(project=project, name=name, tags=tag, group=group, job_type=job_type, config=world.config, save_code=True, sync_tensorboard=False, notes=notes)
     wandb.define_metric("custom_epoch")
     wandb.define_metric(f"{world.config['dataset']}"+'/loss', step_metric='custom_epoch')
@@ -137,6 +138,11 @@ def main():
     print('precal cost : ',end-start)
     cprint('[PRECALCULATE--END]')
 
+    cprint('[SAMPLER--START]')
+    sampler = precalcul.sampler(dataset=dataset, precal=precal)
+    cprint('[SAMPLER--END]')
+    
+
     models = {'LightGCN':model.LightGCN}
     Recmodel = models[world.config['model']](world.config, dataset, precal).to(world.device)
 
@@ -161,7 +167,7 @@ def main():
         pass
     
 
-    losss = {'Adaptive':loss.Adaptive_softmax_loss}
+    losss = {'Adaptive':loss.Adaptive_softmax_loss, 'simple_Adaptive':loss.Adaptive_loss}
     total_loss = losss[world.config['loss']](world.config, Recmodel, precal, homophily)
     
     try:
@@ -185,11 +191,15 @@ def main():
     #     optimizer.add_param_group({'params':augmentation.mlp_edge_model.parameters()})
 
     emb_optimizer = torch.optim.Adam(Recmodel.parameters(), lr=world.config['lr'])
-    aug_optimizer = torch.optim.Adam(augmentation.parameters(), lr=world.config['lr'])    
+    if world.config['augment'] in ['Learner']:
+        aug_optimizer = torch.optim.Adam(augmentation.parameters(), lr=world.config['lr'])    
     emb_optimizer.add_param_group({'params':total_loss.MLP_model.parameters()})#TODO Adaloss 在哪一步更新
     # aug_optimizer = torch.optim.Adam([{'params':augmentation.GNN_encoder.parameters()}, 
     #                                 {'params':augmentation.mlp_edge_model.parameters()}], lr=world.config['lr'])
-    optimizer = {'emb':emb_optimizer, 'aug':aug_optimizer}
+    if world.config['augment'] in ['Learner']:
+        optimizer = {'emb':emb_optimizer, 'aug':aug_optimizer}
+    else:
+        optimizer = {'emb':emb_optimizer}
     quantify = visual.Quantify(dataset, Recmodel, precal)
 
 
@@ -223,7 +233,7 @@ def main():
                     
             cprint('[TRAIN]')
             start_train = time.time()
-            avg_loss = train.train(dataset, Recmodel, augmentation, epoch, optimizer)
+            avg_loss = train.train(sampler, Recmodel, augmentation, epoch, optimizer)
             end_train = time.time()
             wandb.log({ f"{world.config['dataset']}"+'/loss': avg_loss})
             wandb.log({f"{world.config['dataset']}"+f"/training_time": end_train - start_train})
@@ -289,9 +299,9 @@ def main():
             during = time.time() - start
             print(f"total time cost of epoch {epoch}: ", during)
 
-            if world.config['loss'] == 'Adaptive' and world.config['if_adaptive']==1:
+            if world.config['loss'] in ['Adaptive', 'simple_Adaptive'] and world.config['if_adaptive']==1:
                 #plot MLP(pop)
-                # plot_MLP(epoch, precal, total_loss)
+                # plot_MLP(epoch, precal, total_loss)TODO
                 pass
                 
 
diff --git a/pyg_code/model.py b/pyg_code/model.py
index e5d5a07..2118db0 100644
--- a/pyg_code/model.py
+++ b/pyg_code/model.py
@@ -12,6 +12,7 @@ from precalcul import precalculate
 from torch_geometric.nn import LGConv
 from torch_geometric.nn import GCNConv
 from torch.nn import ModuleList
+import numpy as np
 
 class LGN_Encoder(torch.nn.Module):
     def __init__(self, n_layers, num_users, num_items):
@@ -109,6 +110,34 @@ class LightGCN(nn.Module):
         users, items = torch.split(out, [self.num_users, self.num_items])
         return users, items
     
+    def computer_per_layer(self):
+        """
+        vanilla LightGCN. No dropout used, return final embedding for rec. 
+        """
+        users_emb0 = self.embedding_user.weight
+        items_emb0 = self.embedding_item.weight
+        x = torch.cat([users_emb0, items_emb0])
+        embs_per_layer = []
+        embs_per_layer.append(x)
+        out = x * self.alpha
+        for i in range(self.n_layers):
+            x = self.convs[i](x, self.edge_index)
+            embs_per_layer.append(x)
+            out = out + x * self.alpha
+        users, items = torch.split(out, [self.num_users, self.num_items])
+        return users, items, embs_per_layer
+    
+    # def mixup(self, x1, x2, y1=None, y2=None):
+    #     alpha = 2.
+    #     beta = 2.
+    #     size = [len(x1), 1]
+    #     l = np.random.beta(alpha, beta, size)
+    #     mixed_x = torch.tensor(l, dtype=torch.float32).to(x1.device) * x1 + torch.tensor(1-l, dtype=torch.float32).to(x2.device) * x2
+    #     if y1 is None:
+    #         return mixed_x, None
+    #     else:
+    #         mixed_y = torch.tensor(l, dtype=torch.float32).to(y1.device) * y1 + torch.tensor(1-l, dtype=torch.float32).to(y2.device) * y2
+    #         return mixed_x, mixed_y
 
     def view_computer(self, x, edge_index, edge_weight=None):
         try:
@@ -164,4 +193,8 @@ class LightGCN(nn.Module):
         neg_scores = torch.sum(neg_scores, dim=1)
         # mean or sum
         loss = torch.sum(torch.nn.functional.softplus(-(pos_scores - neg_scores)))#TODO SOFTPLUS()!!!
-        return loss, reg_loss
\ No newline at end of file
+        return loss, reg_loss
+    
+
+class classifier():
+    pass
\ No newline at end of file
diff --git a/pyg_code/parse.py b/pyg_code/parse.py
index 491a6c1..22fd4bc 100644
--- a/pyg_code/parse.py
+++ b/pyg_code/parse.py
@@ -46,7 +46,7 @@ def parse_args():
     parser.add_argument('--dataset', type=str, default='yelp2018', help="dataset:[yelp2018,  gawalla, ifashion, amazon-book, last-fm, MIND]") 
     parser.add_argument('--seed', type=int, default=2023, help="random seed")
     parser.add_argument('--loss', type=str, default='Adaptive', help="loss function: Adaptive")
-    parser.add_argument('--augment', type=str, default='Learner', help="Augmentation: No, Adaptive, Learner")    
+    parser.add_argument('--augment', type=str, default='No', help="Augmentation: No, Adaptive, Learner")    
     parser.add_argument('--centroid_mode', type=str, default='eigenvector', help="Centroid mode: degree, pagerank, eigenvector")
     parser.add_argument('--commonNeighbor_mode', type=str, default='SC', help="Common Neighbor mode: JS, SC, CN, LHN")
     parser.add_argument('--adaptive_method', type=str, default='mlp', help="Adaptive coef method: centroid, commonNeighbor, homophily, mlp")
@@ -58,6 +58,7 @@ def parse_args():
     parser.add_argument('--adaloss_mode', type=str, default='pos', help="mode of AdaLoss: pos, pos+neg, pos+neg+cl")
     parser.add_argument('--if_adaptive', type=int, default=1, help="=1: use adaptive coef. =0: use +1.")
     parser.add_argument('--freeze_mlp', type=int, default=500, help="freeze MLP parameters after n epochs")
+    parser.add_argument('--sampling', type=str, default='uij', help="sampling method")
     #===========================================================================================================================================
     parser.add_argument('--c', type=str, default='testing', help="note something for this experiment")
 
diff --git a/pyg_code/precalcul.py b/pyg_code/precalcul.py
index a4f14a5..a77e88e 100644
--- a/pyg_code/precalcul.py
+++ b/pyg_code/precalcul.py
@@ -16,6 +16,8 @@ import os
 import time
 from scipy.sparse import csr_matrix
 import torch_sparse
+from torch.utils.data import Dataset
+import random
 
 #=============================================================Overall Precalculate============================================================#
 class precalculate():
@@ -663,4 +665,59 @@ class SVD():
         val = torch.ones(graph.values().shape[0]).to(world.device)
         num_nodes = graph.shape[0]
         adj = torch.sparse.FloatTensor(graph.indices(), val, torch.Size([num_nodes, num_nodes]))
-        return adj
\ No newline at end of file
+        return adj
+    
+
+class sampler(Dataset):
+    def __init__(self, dataset, precal):
+        super(sampler, self).__init__()
+        self.traindataSize = dataset.traindataSize
+        self.trainUser = dataset.trainUser
+        self.m_item = dataset.m_item
+        self._allPos = dataset._allPos
+        self.reverse_ItemPopGroupDict = precal.popularity.reverse_ItemPopGroupDict
+        self.ItemPopGroupDict = precal.popularity.ItemPopGroupDict
+
+    def __len__(self):
+        return self.traindataSize
+
+    def __getitem__(self, idx):
+        '''
+        input: user在trainUser列表中的idx
+        output: 随机三元组(user, pos, neg) or (user, pos, pos', neg)
+        pos'的popgroup和pos不同
+        '''
+        if world.config['sampling'] == 'uij':
+            user = self.trainUser[idx]
+            pos = random.choice(self._allPos[user])
+            while True:
+                neg = np.random.randint(0, self.m_item)
+                if neg in self._allPos[user]:
+                    continue
+                else:
+                    break
+            return user, pos, neg
+        
+        elif world.config['sampling'] == 'uiij':
+            user = self.trainUser[idx]
+            pos1 = random.choice(self._allPos[user])
+            group1 = self.reverse_ItemPopGroupDict[pos1]
+            
+            for i in range(20):#若20次采样都没有获得不同pop分组的另一个正样本则随机采样pos2
+                pos2 = random.choice(self._allPos[user])
+                if pos2 in self.ItemPopGroupDict[group1]:
+                    continue
+                else:
+                    break
+
+            # while True:
+            #     neg = np.random.randint(0, self.m_item)
+            #     if neg in self._allPos[user]:
+            #         continue
+            #     else:
+            #         break
+            # return user, pos1, pos2, neg
+            return user, pos1, pos2
+        
+        else:
+            raise(TypeError)    
\ No newline at end of file
diff --git a/pyg_code/procedure.py b/pyg_code/procedure.py
index 32097d1..11d8b77 100644
--- a/pyg_code/procedure.py
+++ b/pyg_code/procedure.py
@@ -25,26 +25,72 @@ class Train():
         self.INFONCE = loss.InfoNCE_loss()
         self.BPR = loss.BPR()
 
-    def train(self, dataset, Recmodel, augmentation, epoch, optimizer):
+    def train(self, sampler, Recmodel, augmentation, epoch, optimizer):
         Recmodel:LightGCN = Recmodel
         batch_size = world.config['batch_size']
-        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0)#每个batch为batch_size对(user, pos_item, neg_item), 见Dataset.__getitem__
+        dataloader = DataLoader(sampler, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0)#每个batch为batch_size对(user, pos_item, neg_item), 见Dataset.__getitem__
 
         total_batch = len(dataloader)
         aver_loss = 0.
 
         for batch_i, train_data in tqdm(enumerate(dataloader), desc='training'):
-            batch_users = train_data[0].long().to(world.device)
-            batch_pos = train_data[1].long().to(world.device)
-            batch_neg = train_data[2].long().to(world.device)
+            if world.config['sampling'] == 'uij':
+                batch_users = train_data[0].long().to(world.device)
+                batch_pos = train_data[1].long().to(world.device)
+                batch_neg = train_data[2].long().to(world.device)
+            elif world.config['sampling'] == 'uiij':
+                batch_users = train_data[0].long().to(world.device)
+                batch_pos1 = train_data[1].long().to(world.device)
+                batch_pos2 = train_data[2].long().to(world.device)
+                # batch_neg = train_data[3].long().to(world.device)
+            else:
+                pass
+            # batch_users = train_data[0].long().to(world.device)
+            # batch_pos = train_data[1].long().to(world.device)
+            # batch_neg = train_data[2].long().to(world.device)
             
-            l_all = self.train_all(Recmodel, augmentation, batch_users, batch_pos, batch_neg, optimizer, epoch)
+            l_all = self.train_now(Recmodel, augmentation, batch_users, batch_pos1, batch_pos2, optimizer, epoch)
 
             aver_loss += l_all.cpu().item()
         aver_loss = aver_loss / (total_batch)
         print(f'EPOCH[{epoch}]:loss {aver_loss:.3f}')
         return aver_loss
-    
+
+    def train_now(self, Recmodel, augmentation, batch_users, batch_pos1, batch_pos2, optimizer, epoch):
+        all_users, all_items = Recmodel.computer()
+        users_emb = all_users[batch_users]
+        pos_emb1 = all_items[batch_pos1]
+        pos_emb2 = all_items[batch_pos2]
+        # neg_emb = all_items[batch_neg]
+        users_emb_ego = Recmodel.embedding_user(batch_users)
+        pos_emb_ego1 = Recmodel.embedding_item(batch_pos1)
+        pos_emb_ego2 = Recmodel.embedding_item(batch_pos2)
+
+        reg = (1/6)*(users_emb_ego.norm(2).pow(2) + pos_emb_ego1.norm(2).pow(2) + pos_emb_ego2.norm(2).pow(2))/len(batch_users)
+
+        # cl = self.INFONCE.cal_infonce_loss(users_emb, pos_emb1) + self.INFONCE.cal_infonce_loss(users_emb, pos_emb2) + self.INFONCE.cal_infonce_loss(users_emb, pos_aug)
+        # cl = cl*(1/3)
+
+        # loss = cl + world.config['weight_decay']*reg
+
+        ada_coef1 = self.loss.get_coef_adaptive(batch_users, batch_pos1, method='mlp', mode=world.config['centroid_mode'])
+        ada_coef2 = self.loss.get_coef_adaptive(batch_users, batch_pos2, method='mlp', mode=world.config['centroid_mode'])
+
+        pos_aug, ada_coef3 = self.mixup(pos_emb_ego1, pos_emb_ego2, ada_coef1, ada_coef2)
+
+        loss_ada1 = self.loss.adaptive_loss(users_emb, pos_emb1, ada_coef1)
+        loss_ada2 = self.loss.adaptive_loss(users_emb, pos_emb2, ada_coef2)
+        loss_ada3 = self.loss.adaptive_loss(users_emb, pos_aug, ada_coef3)
+
+        loss = world.config['weight_decay']*reg + loss_ada1*(1/3) + loss_ada2*(1/3) + loss_ada3*(1/3)*0.2
+
+        optimizer['emb'].zero_grad()
+        loss.backward()
+        optimizer['emb'].step()
+
+        return loss
+
+
     def train_batch(self, Recmodel, augmentation, batch_users, batch_pos, batch_neg, optimizer, epoch):
         #========================train Augmentation==========================
         #计算增强视图下的表示
@@ -289,6 +335,18 @@ class Train():
 
         return loss
     
+    def mixup(self, x1, x2, y1=None, y2=None):
+        alpha = 2.
+        beta = 2.
+        size = [len(x1), 1]
+        l = np.random.beta(alpha, beta, size)
+        mixed_x = torch.tensor(l, dtype=torch.float32).to(x1.device) * x1 + torch.tensor(1-l, dtype=torch.float32).to(x2.device) * x2
+        if y1 is None:
+            return mixed_x, None
+        else:
+            mixed_y = torch.tensor(l, dtype=torch.float32).to(y1.device) * y1 + torch.tensor(1-l, dtype=torch.float32).to(y2.device) * y2
+            return mixed_x, mixed_y
+    
 class Test():
     def __init__(self):
         pass
diff --git a/pyg_code/world.py b/pyg_code/world.py
index 4310993..1cfefb0 100644
--- a/pyg_code/world.py
+++ b/pyg_code/world.py
@@ -59,6 +59,7 @@ config['if_valid'] = args.if_valid
 config['adaloss_mode'] = args.adaloss_mode
 config['if_adaptive'] = args.if_adaptive
 config['freeze_mlp'] = args.freeze_mlp
+config['sampling'] = args.sampling
 config['comment'] = args.comment
 #WandB
 config['project'] = args.project
