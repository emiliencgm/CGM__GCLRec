diff --git a/pyg_code/procedure.py b/pyg_code/procedure.py
index 4beced6..dabefd1 100644
--- a/pyg_code/procedure.py
+++ b/pyg_code/procedure.py
@@ -111,7 +111,7 @@ class Train():
 
         return loss_aug, loss_emb
     
-    def train_all(self, Recmodel, augmentation, batch_users, batch_pos, batch_neg, optimizer, epoch):
+    def train_all_origin(self, Recmodel, augmentation, batch_users, batch_pos, batch_neg, optimizer, epoch):
         #========================train Embeddings==========================
         #使用BPR_Contrast来训练Embedding
         Recmodel.train()
@@ -289,6 +289,71 @@ class Train():
 
         return loss
 
+
+    def train_all(self, Recmodel, augmentation, batch_users, batch_pos, batch_neg, optimizer, epoch):
+        #========================train Embeddings==========================
+        Recmodel.train()
+        self.loss.MLP_model.train()
+        augmentation.eval()
+
+        # Perform inner loop optimization using MAML
+        for inner_batch_users, inner_batch_pos, inner_batch_neg in zip(batch_users, batch_pos, batch_neg):
+            optimizer['emb'].zero_grad()
+
+            users_emb0 = Recmodel.embedding_user.weight
+            items_emb0 = Recmodel.embedding_item.weight
+
+            userEmb0,  posEmb0 = users_emb0[inner_batch_users], items_emb0[inner_batch_pos]
+            reg = torch.mean(0.5 * torch.norm(userEmb0) ** 2 +  0.5 * torch.norm(posEmb0) ** 2)
+
+            x = torch.cat([users_emb0, items_emb0])
+            edge_index = Recmodel.edge_index
+            users, items = Recmodel.view_computer(x, edge_index, edge_weight=None)
+
+            users_emb, pos_emb, neg_emb = users[inner_batch_users], items[inner_batch_pos], items[inner_batch_neg]
+            loss_ada = self.loss.adaptive_softmax_loss(users_emb, pos_emb, None, inner_batch_users, inner_batch_pos, None, None, None, None, None, epoch)
+
+            aug_users1, aug_items1 = users, items
+
+            edge_weight = augmentation.forward(x.detach(), edge_index)
+            aug_users2, aug_items2 = Recmodel.view_computer(x, edge_index, edge_weight=edge_weight.detach())
+            batch_aug_users, batch_aug_items = aug_users2[inner_batch_users], aug_items2[inner_batch_pos]
+
+            loss_ada_aug = self.loss.adaptive_softmax_loss(batch_aug_users, batch_aug_items, None, inner_batch_users, inner_batch_pos, None, None, None, None, None, epoch)
+
+            loss_emb = world.config['weight_decay']*reg + 0.1*loss_ada + 0.1*loss_ada_aug
+            loss_emb.backward()
+            optimizer['emb'].step()
+
+        #========================train Augmentation==========================
+        Recmodel.eval()
+        self.loss.MLP_model.eval()
+        augmentation.train()
+        optimizer['aug'].zero_grad()
+
+        users_emb0 = Recmodel.embedding_user.weight.detach()
+        items_emb0 = Recmodel.embedding_item.weight.detach()
+
+        x = torch.cat([users_emb0, items_emb0])
+        edge_index = Recmodel.edge_index
+        users, items = Recmodel.view_computer(x, edge_index, edge_weight=None)
+        edge_weight = augmentation.forward(x, edge_index)
+        aug_users, aug_items = Recmodel.view_computer(x, edge_index, edge_weight=edge_weight)
+
+        loss_infonce = -self.INFONCE.infonce_loss(batch_users, batch_pos, users, items, aug_users, aug_items)
+
+        loss_instance = self.calc_instance_loss(users[batch_users], aug_users[batch_users]) + self.calc_instance_loss(items[batch_pos], aug_items[batch_pos])
+
+        loss_aug = 0. * loss_infonce + 0.1 * loss_instance
+        loss_aug.requires_grad_(True)
+        loss_aug.backward()
+        optimizer['aug'].step()
+
+        return loss_aug + loss_emb
+
+
+
+
 class Test():
     def __init__(self):
         pass
