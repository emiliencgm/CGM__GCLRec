diff --git a/pyg_code/__pycache__/augment.cpython-310.pyc b/pyg_code/__pycache__/augment.cpython-310.pyc
index e202b2f..2def07f 100644
Binary files a/pyg_code/__pycache__/augment.cpython-310.pyc and b/pyg_code/__pycache__/augment.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/dataloader.cpython-310.pyc b/pyg_code/__pycache__/dataloader.cpython-310.pyc
index 1c60fd5..a1a4ae0 100644
Binary files a/pyg_code/__pycache__/dataloader.cpython-310.pyc and b/pyg_code/__pycache__/dataloader.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/homophily.cpython-310.pyc b/pyg_code/__pycache__/homophily.cpython-310.pyc
index 2105f99..c469e1c 100644
Binary files a/pyg_code/__pycache__/homophily.cpython-310.pyc and b/pyg_code/__pycache__/homophily.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/kmeans_gpu.cpython-310.pyc b/pyg_code/__pycache__/kmeans_gpu.cpython-310.pyc
index 77af26b..7f875a8 100644
Binary files a/pyg_code/__pycache__/kmeans_gpu.cpython-310.pyc and b/pyg_code/__pycache__/kmeans_gpu.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/loss.cpython-310.pyc b/pyg_code/__pycache__/loss.cpython-310.pyc
index f9257b5..ba69684 100644
Binary files a/pyg_code/__pycache__/loss.cpython-310.pyc and b/pyg_code/__pycache__/loss.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/model.cpython-310.pyc b/pyg_code/__pycache__/model.cpython-310.pyc
index 635c50f..d39a123 100644
Binary files a/pyg_code/__pycache__/model.cpython-310.pyc and b/pyg_code/__pycache__/model.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/parse.cpython-310.pyc b/pyg_code/__pycache__/parse.cpython-310.pyc
index e3c7d51..82e3a8b 100644
Binary files a/pyg_code/__pycache__/parse.cpython-310.pyc and b/pyg_code/__pycache__/parse.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/precalcul.cpython-310.pyc b/pyg_code/__pycache__/precalcul.cpython-310.pyc
index 31307ca..2899e1b 100644
Binary files a/pyg_code/__pycache__/precalcul.cpython-310.pyc and b/pyg_code/__pycache__/precalcul.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/procedure.cpython-310.pyc b/pyg_code/__pycache__/procedure.cpython-310.pyc
index 243bf99..c3207a4 100644
Binary files a/pyg_code/__pycache__/procedure.cpython-310.pyc and b/pyg_code/__pycache__/procedure.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/utils.cpython-310.pyc b/pyg_code/__pycache__/utils.cpython-310.pyc
index 40b27a3..18ac6de 100644
Binary files a/pyg_code/__pycache__/utils.cpython-310.pyc and b/pyg_code/__pycache__/utils.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/visual.cpython-310.pyc b/pyg_code/__pycache__/visual.cpython-310.pyc
index 7403999..19a022c 100644
Binary files a/pyg_code/__pycache__/visual.cpython-310.pyc and b/pyg_code/__pycache__/visual.cpython-310.pyc differ
diff --git a/pyg_code/__pycache__/world.cpython-310.pyc b/pyg_code/__pycache__/world.cpython-310.pyc
index 12fe0c4..9034de1 100644
Binary files a/pyg_code/__pycache__/world.cpython-310.pyc and b/pyg_code/__pycache__/world.cpython-310.pyc differ
diff --git a/pyg_code/dataloader.py b/pyg_code/dataloader.py
index 31e30e0..db33bf9 100644
--- a/pyg_code/dataloader.py
+++ b/pyg_code/dataloader.py
@@ -21,7 +21,7 @@ from time import time
 import networkx as nx
 from torch_geometric.data import Data
 
-class dataset(Dataset):
+class dataset():
     """
     Dataset type for pytorch \n
     Incldue graph information
@@ -355,24 +355,3 @@ class dataset(Dataset):
         edge_indice = torch.sparse.FloatTensor(index, val, (self.n_user, self.m_item))
         edge_indice = edge_indice.coalesce()
         return edge_indice
-
-    '''
-    Dataset的所有子类都应该重写方法__len__(), __getitem__()
-    '''
-    def __len__(self):
-        return self.traindataSize
-
-    def __getitem__(self, idx):
-        '''
-        input: user在trainUser列表中的idx
-        output: 随机三元组(user, pos, neg)
-        '''
-        user = self.trainUser[idx]
-        pos = random.choice(self._allPos[user])
-        while True:
-            neg = np.random.randint(0, self.m_item)
-            if neg in self._allPos[user]:
-                continue
-            else:
-                break
-        return user, pos, neg
diff --git a/pyg_code/main.py b/pyg_code/main.py
index 495e796..af0c758 100644
--- a/pyg_code/main.py
+++ b/pyg_code/main.py
@@ -137,6 +137,11 @@ def main():
     print('precal cost : ',end-start)
     cprint('[PRECALCULATE--END]')
 
+    cprint('[SAMPLER--START]')
+    sampler = precalcul.sampler(dataset=dataset, precal=precal)
+    cprint('[SAMPLER--END]')
+    
+
     models = {'LightGCN':model.LightGCN}
     Recmodel = models[world.config['model']](world.config, dataset, precal).to(world.device)
 
@@ -223,7 +228,7 @@ def main():
                     
             cprint('[TRAIN]')
             start_train = time.time()
-            avg_loss = train.train(dataset, Recmodel, augmentation, epoch, optimizer)
+            avg_loss = train.train(sampler, Recmodel, augmentation, epoch, optimizer)
             end_train = time.time()
             wandb.log({ f"{world.config['dataset']}"+'/loss': avg_loss})
             wandb.log({f"{world.config['dataset']}"+f"/training_time": end_train - start_train})
diff --git a/pyg_code/parse.py b/pyg_code/parse.py
index 491a6c1..25cee30 100644
--- a/pyg_code/parse.py
+++ b/pyg_code/parse.py
@@ -58,6 +58,7 @@ def parse_args():
     parser.add_argument('--adaloss_mode', type=str, default='pos', help="mode of AdaLoss: pos, pos+neg, pos+neg+cl")
     parser.add_argument('--if_adaptive', type=int, default=1, help="=1: use adaptive coef. =0: use +1.")
     parser.add_argument('--freeze_mlp', type=int, default=500, help="freeze MLP parameters after n epochs")
+    parser.add_argument('--sampling', type=str, default='uij', help="sampling method")
     #===========================================================================================================================================
     parser.add_argument('--c', type=str, default='testing', help="note something for this experiment")
 
diff --git a/pyg_code/precalcul.py b/pyg_code/precalcul.py
index a4f14a5..74fd3fb 100644
--- a/pyg_code/precalcul.py
+++ b/pyg_code/precalcul.py
@@ -16,6 +16,8 @@ import os
 import time
 from scipy.sparse import csr_matrix
 import torch_sparse
+from torch.utils.data import Dataset
+import random
 
 #=============================================================Overall Precalculate============================================================#
 class precalculate():
@@ -663,4 +665,57 @@ class SVD():
         val = torch.ones(graph.values().shape[0]).to(world.device)
         num_nodes = graph.shape[0]
         adj = torch.sparse.FloatTensor(graph.indices(), val, torch.Size([num_nodes, num_nodes]))
-        return adj
\ No newline at end of file
+        return adj
+    
+
+class sampler(Dataset):
+    def __init__(self, dataset, precal):
+        self.traindataSize = dataset.traindataSize
+        self.trainUser = dataset.trainUser
+        self.m_item = dataset.m_item
+        self._allPos = dataset._allPos
+        self.reverse_ItemPopGroupDict = precal.popularity.reverse_ItemPopGroupDict
+        self.ItemPopGroupDict = precal.popularity.ItemPopGroupDict
+
+    def __len__(self):
+        return self.traindataSize
+
+    def __getitem__(self, idx):
+        '''
+        input: user在trainUser列表中的idx
+        output: 随机三元组(user, pos, neg) or (user, pos, pos', neg)
+        pos'的popgroup和pos不同
+        '''
+        if world.config['sampling'] == 'uij':
+            user = self.trainUser[idx]
+            pos = random.choice(self._allPos[user])
+            while True:
+                neg = np.random.randint(0, self.m_item)
+                if neg in self._allPos[user]:
+                    continue
+                else:
+                    break
+            return user, pos, neg
+        
+        elif world.config['sampling'] == 'uiij':
+            user = self.trainUser[idx]
+            pos1 = random.choice(self._allPos[user])
+            group1 = self.reverse_ItemPopGroupDict[pos1]
+            
+            for i in range(10):#若100次采样都没有获得不同pop分组的另一个正样本则随机采样pos2
+                pos2 = random.choice(self._allPos[user])
+                if pos2 in self.ItemPopGroupDict[group1]:
+                    continue
+                else:
+                    break
+
+            while True:
+                neg = np.random.randint(0, self.m_item)
+                if neg in self._allPos[user]:
+                    continue
+                else:
+                    break
+            return user, pos1, pos2, neg
+        
+        else:
+            raise(TypeError)    
\ No newline at end of file
diff --git a/pyg_code/procedure.py b/pyg_code/procedure.py
index 32097d1..5aff35a 100644
--- a/pyg_code/procedure.py
+++ b/pyg_code/procedure.py
@@ -25,10 +25,10 @@ class Train():
         self.INFONCE = loss.InfoNCE_loss()
         self.BPR = loss.BPR()
 
-    def train(self, dataset, Recmodel, augmentation, epoch, optimizer):
+    def train(self, sampler, Recmodel, augmentation, epoch, optimizer):
         Recmodel:LightGCN = Recmodel
         batch_size = world.config['batch_size']
-        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0)#每个batch为batch_size对(user, pos_item, neg_item), 见Dataset.__getitem__
+        dataloader = DataLoader(sampler, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0)#每个batch为batch_size对(user, pos_item, neg_item), 见Dataset.__getitem__
 
         total_batch = len(dataloader)
         aver_loss = 0.
@@ -44,6 +44,9 @@ class Train():
         aver_loss = aver_loss / (total_batch)
         print(f'EPOCH[{epoch}]:loss {aver_loss:.3f}')
         return aver_loss
+
+    def train_CL(self, Recmodel, augmentation, batch_users, batch_pos, batch_neg, optimizer, epoch):
+        pass
     
     def train_batch(self, Recmodel, augmentation, batch_users, batch_pos, batch_neg, optimizer, epoch):
         #========================train Augmentation==========================
diff --git a/pyg_code/world.py b/pyg_code/world.py
index 4310993..1cfefb0 100644
--- a/pyg_code/world.py
+++ b/pyg_code/world.py
@@ -59,6 +59,7 @@ config['if_valid'] = args.if_valid
 config['adaloss_mode'] = args.adaloss_mode
 config['if_adaptive'] = args.if_adaptive
 config['freeze_mlp'] = args.freeze_mlp
+config['sampling'] = args.sampling
 config['comment'] = args.comment
 #WandB
 config['project'] = args.project
